\section{Plans \& Future Work}

\subsection{Approach}
As noted in section~\ref{literature_survey}, most of the work that I
have surveyed so far has been on still images or recorded video. What
we are trying to achieve as part of CDI project is to detect and
analyze mutual inter-personal and inter-device communications on the
go. Typical examples would be a poster session at a conference where
there are actors with devices. Some of the actors are not permanent to
scene but enter and leave the person-device ecosystem
dynamically. Another example is a meeting room where most of the
device carrying participants are practically stationary but we have a
small number of individuals entering or leaving the session with their
personal devices. These devices might dynamically register and
unregister with its peers or the main display control.

\subsection{Detailed plan}

Here I present the break up of my schedule for research work for the
upcoming summer session.

\subsubsection{Fully understand capabilities of Walabot}
Now that I better understand how to manipulate and consume the data
generated system, I am in a better position to further explore the
capabilities. Up until now, I had only been toying with the 2D slices
of 3D data. I recently had the opportunity to spend some time with 3D
visualization tools. One of the tasks I am interested in doing is to
read the whole 3D cube of data as provided by Walabot in the spherical
co-ordinate system ($R, \phi, \theta$) and plot them after applying
3-D coordinate transformation. This should enable me to view the
dumped data in ParaView.

\subsubsection{Generate ground truth data}
As discussed(in prior in-person meetings) before, the first step is to
use Vicon motion tracking system at EVL and generate labeled data as
ground truth data for model F-Formations. This will have to follow
CITI certification. Then I should be able to collaborate with Minh to
get familiar with the Vicon/Omicron system and thereafter design
experiments for data collection.

\subsubsection{Build a software framework for multi-sensor based tracking}
Use other devices like Kinect, Walabot, camera and one or more
combinations of these devices to identify groups. Augment data from
several sensors and design a sytem that provides a seemless access to
3-D motion data.

\subsubsection{Run unsupervised learning on data to detect groups}
The next step is to use the aforementioned service to detect clusters
of humans using unsupervised
learning~\cite{James:2014:ISL:2517747}. The idea is to perform an
\emph{Expectation-Maximization(EM)}~\cite{10.2307/2984875} style
learning on the 3-D sensor data to detect groups of people and
devices.

\subsubsection{Understand HCI better}
Understand more HCI specific literature better. Part of understanding
the field of HCI also depends on the social aspects of human
interpersonal behavior.

\subsubsection{Prepare for conference paper deadline}
Start collecting and recording facts, figures and tables as we conduct
the experiments. Record all significant finding on the project Wiki.
